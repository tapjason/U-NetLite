{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e255f5-5a73-4a6f-9c70-f14cfea12fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import gc\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from models.unet import UNet\n",
    "from models.enhanced_unet import EnhancedUNet, SpatialAttentionUNet, UltraLightUNet\n",
    "from utils.losses import BCEDiceLoss\n",
    "from utils.metrics import dice_coefficient, iou_coefficient\n",
    "from data.isic_dataset import ISICDataset, load_isic_data\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811a2b7a-ca95-4525-8670-c38632acb1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2594 image-mask pairs\n",
      "Train: 1815, Validation: 389, Test: 390\n",
      "ISIC Dataset Statistics:\n",
      "Training samples: 1815\n",
      "Validation samples: 389\n",
      "Test samples: 390\n"
     ]
    }
   ],
   "source": [
    "# Load the ISIC dataset\n",
    "isic_data_path = '../data/isic_2018_task1_data'\n",
    "isic_data = load_isic_data(isic_data_path)\n",
    "\n",
    "# Access the data loaders\n",
    "isic_train_loader = isic_data['train_loader']\n",
    "isic_val_loader = isic_data['val_loader']\n",
    "isic_test_loader = isic_data['test_loader']\n",
    "\n",
    "# Visualize some samples from the training dataset\n",
    "print(\"Visualizing ISIC training samples:\")\n",
    "isic_data['visualize_samples'](isic_data['train_dataset'])\n",
    "\n",
    "# Visualize validation samples as well\n",
    "print(\"Visualizing ISIC validation samples:\")\n",
    "isic_data['visualize_samples'](isic_data['val_dataset'])\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"ISIC Dataset Statistics:\")\n",
    "print(f\"Training samples: {isic_data['num_train_samples']}\")\n",
    "print(f\"Validation samples: {isic_data['num_val_samples']}\")\n",
    "print(f\"Test samples: {isic_data['num_test_samples']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c04fc7da-faee-4808-a81c-97b47bba11e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "unet_standard summary:\n",
      "Total parameters: 31,037,633\n",
      "\n",
      "unet_with_depthwise summary:\n",
      "Total parameters: 5,988,252\n",
      "\n",
      "unet_with_se_depthwise summary:\n",
      "Total parameters: 6,206,364\n",
      "\n",
      "unet_with_se_depthwise_reduced summary:\n",
      "Total parameters: 6,097,308\n",
      "\n",
      "unet_with_spatial_attn summary:\n",
      "Total parameters: 6,206,756\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'unet_standard': UNet(n_channels=3, n_classes=1).to(device),\n",
    "    'unet_with_depthwise': EnhancedUNet(n_channels=3, n_classes=1, use_se=False, use_lightweight=True).to(device),\n",
    "    'unet_with_se_depthwise': EnhancedUNet(n_channels=3, n_classes=1, use_se=True, use_lightweight=True).to(device),\n",
    "    'unet_with_se_depthwise_reduced': EnhancedUNet(n_channels=3, n_classes=1, use_se=True, use_lightweight=True, se_reduction=32).to(device),\n",
    "    'unet_with_spatial_attn': SpatialAttentionUNet(n_channels=3, n_classes=1, use_se=True, use_lightweight=True).to(device),\n",
    "}\n",
    "\n",
    "# Print model architecture summary\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name} summary:\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6baa7650-ac86-4119-a11c-825765355634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_isic_model(model, model_name, train_loader, val_loader, num_epochs=25, \n",
    "                     model_dir=\"../saved_models/isic/\", force_train=False, resume_training=True):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    save_dir = os.path.join(model_dir, model_name)\n",
    "    best_model_path = os.path.join(save_dir, 'best_model.pth')\n",
    "    checkpoint_path = os.path.join(save_dir, 'checkpoint.pth')\n",
    "    \n",
    "    criterion = BCEDiceLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, patience=5, factor=0.5, min_lr=1e-6)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_dices = []\n",
    "    val_ious = []\n",
    "    learning_rates = []\n",
    "    best_val_dice = 0\n",
    "    start_epoch = 0\n",
    "    \n",
    "    if os.path.exists(checkpoint_path) and resume_training and not force_train:\n",
    "        print(f\"Loading checkpoint from {checkpoint_path} to resume training.\")\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        best_val_dice = checkpoint['val_dice']\n",
    "        \n",
    "        if 'train_losses' in checkpoint:\n",
    "            train_losses = checkpoint['train_losses']\n",
    "            val_losses = checkpoint['val_losses']\n",
    "            val_dices = checkpoint['val_dices']\n",
    "            val_ious = checkpoint.get('val_ious', [])\n",
    "            learning_rates = checkpoint.get('learning_rates', [])\n",
    "        \n",
    "        print(f\"Resuming from epoch {start_epoch} with best validation Dice: {best_val_dice:.4f}\")\n",
    "    \n",
    "    # Check if best model exists\n",
    "    elif os.path.exists(best_model_path) and not force_train:\n",
    "        print(f\"Found existing model at {best_model_path}. Skipping training.\")\n",
    "        model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "        \n",
    "        # Evaluate the loaded model on validation set\n",
    "        model.eval()\n",
    "        epoch_dice = 0\n",
    "        epoch_iou = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                dice = dice_coefficient(outputs, masks)\n",
    "                iou = iou_coefficient(outputs, masks)\n",
    "                \n",
    "                epoch_dice += dice\n",
    "                epoch_iou += iou\n",
    "                batch_count += 1\n",
    "        \n",
    "        val_dice = epoch_dice / batch_count\n",
    "        val_iou = epoch_iou / batch_count\n",
    "        \n",
    "        print(f\"Loaded model performance - Dice: {val_dice:.4f}, IoU: {val_iou:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'best_val_dice': val_dice,\n",
    "            'loaded_from_checkpoint': True\n",
    "        }\n",
    "    \n",
    "    # Memory management\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        learning_rates.append(current_lr)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        for images, masks in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping (reduced for dermoscopic images)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.5)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            batch_count += 1\n",
    "            \n",
    "            if batch_count % 10 == 0:\n",
    "                del images, masks, outputs, loss\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        train_loss = epoch_loss / batch_count\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_loss = 0\n",
    "        epoch_dice = 0\n",
    "        epoch_iou = 0\n",
    "        batch_count = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in val_loader:\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                dice = dice_coefficient(outputs, masks)\n",
    "                iou = iou_coefficient(outputs, masks)\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                epoch_dice += dice\n",
    "                epoch_iou += iou\n",
    "                batch_count += 1\n",
    "                \n",
    "                del images, masks, outputs, loss\n",
    "        \n",
    "        val_loss = epoch_loss / batch_count\n",
    "        val_dice = epoch_dice / batch_count\n",
    "        val_iou = epoch_iou / batch_count\n",
    "        val_losses.append(val_loss)\n",
    "        val_dices.append(val_dice)\n",
    "        val_ious.append(val_iou)\n",
    "    \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1:3d}/{num_epochs} | LR: {current_lr:.6f} | '\n",
    "              f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | '\n",
    "              f'Val Dice: {val_dice:.4f} | Val IoU: {val_iou:.4f}')\n",
    "        \n",
    "        # Save checkpoint every epoch for resuming\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_dice': val_dice,\n",
    "            'val_loss': val_loss,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'val_dices': val_dices,\n",
    "            'val_ious': val_ious,\n",
    "            'learning_rates': learning_rates,\n",
    "            'best_val_dice': best_val_dice\n",
    "        }, os.path.join(save_dir, 'checkpoint.pth'))\n",
    "        \n",
    "        # Save best model based on Dice coefficient\n",
    "        if val_dice > best_val_dice:\n",
    "            best_val_dice = val_dice\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, 'best_model.pth'))\n",
    "            print(f\"Saved new best model with Dice score: {val_dice:.4f}\")\n",
    "        \n",
    "        # Memory cleanup after each epoch\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, 'final_model.pth'))\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_dices': val_dices,\n",
    "        'val_ious': val_ious,\n",
    "        'learning_rates': learning_rates,\n",
    "        'best_val_dice': best_val_dice,\n",
    "        'epochs': num_epochs,\n",
    "        'loaded_from_checkpoint': False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2c34a1-7e2b-4257-ba2f-c670a0b3fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Training unet_standard model on ISIC ====================\n",
      "Loading checkpoint from ../saved_models/isic/unet_standard/checkpoint.pth to resume training.\n",
      "Resuming from epoch 25 with best validation Dice: 0.8762\n",
      "Completed training for unet_standard model on ISIC dataset\n",
      "\n",
      "==================== Training unet_with_depthwise model on ISIC ====================\n",
      "Loading checkpoint from ../saved_models/isic/unet_with_depthwise/checkpoint.pth to resume training.\n",
      "Resuming from epoch 25 with best validation Dice: 0.8869\n",
      "Completed training for unet_with_depthwise model on ISIC dataset\n",
      "\n",
      "==================== Training unet_with_se_depthwise model on ISIC ====================\n",
      "Loading checkpoint from ../saved_models/isic/unet_with_se_depthwise/checkpoint.pth to resume training.\n",
      "Resuming from epoch 25 with best validation Dice: 0.8879\n",
      "Completed training for unet_with_se_depthwise model on ISIC dataset\n",
      "\n",
      "==================== Training unet_with_se_depthwise_reduced model on ISIC ====================\n",
      "Loading checkpoint from ../saved_models/isic/unet_with_se_depthwise_reduced/checkpoint.pth to resume training.\n",
      "Resuming from epoch 25 with best validation Dice: 0.8848\n",
      "Completed training for unet_with_se_depthwise_reduced model on ISIC dataset\n",
      "\n",
      "==================== Training unet_with_spatial_attn model on ISIC ====================\n",
      "Loading checkpoint from ../saved_models/isic/unet_with_spatial_attn/checkpoint.pth to resume training.\n",
      "Resuming from epoch 25 with best validation Dice: 0.8802\n",
      "Completed training for unet_with_spatial_attn model on ISIC dataset\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 25  # Slightly reduced from BUSI as ISIC has more samples\n",
    "isic_results = {}\n",
    "\n",
    "# Clear memory before starting training loop\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*20} Training {model_name} model on ISIC {'='*20}\")\n",
    "    try:\n",
    "        model_results = train_isic_model(\n",
    "            model, \n",
    "            model_name, \n",
    "            isic_train_loader, \n",
    "            isic_val_loader, \n",
    "            num_epochs=num_epochs,\n",
    "            resume_training=True,\n",
    "        )\n",
    "        isic_results[model_name] = model_results\n",
    "        print(f\"Completed training for {model_name} model on ISIC dataset\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {model_name}: {e}\")\n",
    "        continue\n",
    "        \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "# Save all results to file\n",
    "import json\n",
    "import os\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "with open('results/isic_training_results.json', 'w') as f:\n",
    "    # Convert non-serializable data (like tensors) to Python types\n",
    "    serializable_results = {}\n",
    "    for model_name, results in isic_results.items():\n",
    "        if isinstance(results, dict):\n",
    "            serializable_model_results = {}\n",
    "            for k, v in results.items():\n",
    "                if isinstance(v, (list, dict, str, int, float, bool)) or v is None:\n",
    "                    serializable_model_results[k] = v\n",
    "                elif hasattr(v, 'tolist'):\n",
    "                    try:\n",
    "                        serializable_model_results[k] = v.tolist()\n",
    "                    except:\n",
    "                        serializable_model_results[k] = str(v)\n",
    "                else:\n",
    "                    serializable_model_results[k] = str(v)\n",
    "            serializable_results[model_name] = serializable_model_results\n",
    "    \n",
    "    json.dump(serializable_results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0cd570-045e-4b14-ab31-652c7fa62e93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
