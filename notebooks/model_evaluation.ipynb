{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7352fb77-f2d7-40e7-8511-9997be05d655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from thop import profile\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "# Add parent directory to path\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Import project modules\n",
    "from models.unet import UNet\n",
    "from models.enhanced_unet import EnhancedUNet, SpatialAttentionUNet, UltraLightUNet\n",
    "from utils.metrics import dice_coefficient, iou_coefficient, pixel_accuracy\n",
    "from data.isic_dataset import load_isic_data\n",
    "from data.busi_dataset import load_busi_data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "843fee78-78e7-4f8b-9559-d837726f5276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2594 image-mask pairs\n",
      "Train: 1815, Validation: 389, Test: 390\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'isic'\n",
    "\n",
    "\n",
    "\n",
    "if DATASET == 'isic':\n",
    "    data = load_isic_data(dataset_path='../data/isic_2018_task1_data')\n",
    "    \n",
    "elif DATASET == 'busi':\n",
    "    data = load_busi_data(dataset_path='../data/busi_dataset/Dataset_BUSI_with_GT')\n",
    "else:\n",
    "    raise ValueError(\"Unsupported dataset name\")\n",
    "\n",
    "test_loader = data['test_loader']\n",
    "dataset_name = DATASET\n",
    "models = {\n",
    "    'unet_standard': UNet(n_channels=3, n_classes=1).to(device),\n",
    "    'unet_with_depthwise': EnhancedUNet(n_channels=3, n_classes=1, use_se=False, use_lightweight=True).to(device),\n",
    "    'unet_with_se_depthwise': EnhancedUNet(n_channels=3, n_classes=1, use_se=True, use_lightweight=True).to(device),\n",
    "    'unet_with_se_depthwise_reduced': EnhancedUNet(n_channels=3, n_classes=1, use_se=True, use_lightweight=True, se_reduction=32).to(device),\n",
    "    'unet_with_spatial_attn': SpatialAttentionUNet(n_channels=3, n_classes=1, use_se=True, use_lightweight=True).to(device),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a0c829c-5c3d-4fe6-9808-337d6ece8e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: unet_standard\n",
      "Loaded model: unet_with_depthwise\n",
      "Loaded model: unet_with_se_depthwise\n",
      "Loaded model: unet_with_se_depthwise_reduced\n",
      "Loaded model: unet_with_spatial_attn\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    model_path = os.path.join(f'../saved_models/{DATASET}', model_name, 'best_model.pth')\n",
    "    if os.path.exists(model_path):\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "        print(f\"Loaded model: {model_name}\")\n",
    "    else:\n",
    "        print(f\"⚠️  Model file not found for {model_name}: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acf49647-0ba8-4d61-8234-ea5d48bf4462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Computing Efficiency Metrics ===\n",
      "unet_standard:\n",
      "  Parameters: 31,037,633\n",
      "  FLOPs: 54.74 G\n",
      "  Inference time: 7.10 ms\n",
      "unet_with_depthwise:\n",
      "  Parameters: 5,988,252\n",
      "  FLOPs: 14.14 G\n",
      "  Inference time: 4.02 ms\n",
      "unet_with_se_depthwise:\n",
      "  Parameters: 6,206,364\n",
      "  FLOPs: 14.16 G\n",
      "  Inference time: 5.78 ms\n",
      "unet_with_se_depthwise_reduced:\n",
      "  Parameters: 6,097,308\n",
      "  FLOPs: 14.16 G\n",
      "  Inference time: 5.73 ms\n",
      "unet_with_spatial_attn:\n",
      "  Parameters: 6,206,756\n",
      "  FLOPs: 14.16 G\n",
      "  Inference time: 6.33 ms\n",
      "\n",
      "=== Efficiency Summary ===\n",
      "unet_standard                  | Params: 31,037,633 | FLOPs: 54.74 G | Inference: 7.10 ms\n",
      "unet_with_depthwise            | Params: 5,988,252 | FLOPs: 14.14 G | Inference: 4.02 ms\n",
      "unet_with_se_depthwise         | Params: 6,206,364 | FLOPs: 14.16 G | Inference: 5.78 ms\n",
      "unet_with_se_depthwise_reduced | Params: 6,097,308 | FLOPs: 14.16 G | Inference: 5.73 ms\n",
      "unet_with_spatial_attn         | Params: 6,206,756 | FLOPs: 14.16 G | Inference: 6.33 ms\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"Count the number of trainable parameters in the model\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def measure_inference_time(model, input_size=(1, 3, 256, 256), num_iterations=50):\n",
    "    \"\"\"Measure average inference time over multiple iterations\"\"\"\n",
    "    dummy_input = torch.randn(input_size).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(10):\n",
    "            _ = model(dummy_input)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_iterations):\n",
    "            _ = model(dummy_input)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    end_time = time()\n",
    "    \n",
    "    return (end_time - start_time) / num_iterations\n",
    "\n",
    "efficiency_metrics = {}\n",
    "eval_type = 'both'\n",
    "if eval_type in ['efficiency', 'both']:\n",
    "    print(\"\\n=== Computing Efficiency Metrics ===\")\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Parameters\n",
    "        params = count_parameters(model)\n",
    "        \n",
    "        # FLOPs (Floating Point Operations)\n",
    "        dummy_input = torch.randn(1, 3, 256, 256).to(device)\n",
    "        flops, _ = profile(model, inputs=(dummy_input,), verbose=False)\n",
    "        \n",
    "        inference_time = measure_inference_time(model)\n",
    "        \n",
    "        efficiency_metrics[model_name] = {\n",
    "            'params': params,\n",
    "            'flops': flops,\n",
    "            'inference_time': inference_time\n",
    "        }\n",
    "        \n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  Parameters: {params:,}\")\n",
    "        print(f\"  FLOPs: {flops / 1e9:.2f} G\")\n",
    "        print(f\"  Inference time: {inference_time * 1000:.2f} ms\")\n",
    "\n",
    "    os.makedirs(f'../results/{dataset_name}', exist_ok=True)\n",
    "    with open(f'../results/{dataset_name}/efficiency_metrics.json', 'w') as f:\n",
    "        serializable_metrics = {}\n",
    "        for model_name, metrics in efficiency_metrics.items():\n",
    "            serializable_metrics[model_name] = {\n",
    "                'params': int(metrics['params']),\n",
    "                'flops': float(metrics['flops']),\n",
    "                'inference_time': float(metrics['inference_time'])\n",
    "            }\n",
    "        json.dump(serializable_metrics, f, indent=2)\n",
    "\n",
    "print(\"\\n=== Efficiency Summary ===\")\n",
    "for model_name, metrics in efficiency_metrics.items():\n",
    "    print(f\"{model_name:<30} | Params: {metrics['params']:,} | \"\n",
    "          f\"FLOPs: {metrics['flops'] / 1e9:.2f} G | \"\n",
    "          f\"Inference: {metrics['inference_time'] * 1000:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c1da6c7-418a-42e3-9b06-412bde6c8ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating unet_standard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet_standard - Dice: 87.98%, IoU: 78.77%, Acc: 95.27%\n",
      "Evaluating unet_with_depthwise...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet_with_depthwise - Dice: 88.51%, IoU: 79.54%, Acc: 95.27%\n",
      "Evaluating unet_with_se_depthwise...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet_with_se_depthwise - Dice: 89.2%, IoU: 80.65%, Acc: 95.56%\n",
      "Evaluating unet_with_se_depthwise_reduced...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet_with_se_depthwise_reduced - Dice: 89.12%, IoU: 80.52%, Acc: 95.47%\n",
      "Evaluating unet_with_spatial_attn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unet_with_spatial_attn - Dice: 88.91%, IoU: 80.19%, Acc: 95.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Evaluate a model on the test set and return average Dice, IoU, and accuracy\"\"\"\n",
    "    model.eval()\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    accuracy_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(test_loader, desc=\"Evaluating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate metrics\n",
    "            dice = dice_coefficient(outputs, masks)\n",
    "            iou = iou_coefficient(outputs, masks)\n",
    "            acc = pixel_accuracy(outputs, masks)\n",
    "\n",
    "            dice_scores.append(dice)\n",
    "            iou_scores.append(iou)\n",
    "            accuracy_scores.append(acc)\n",
    "\n",
    "    return {\n",
    "        'dice': round(np.mean(dice_scores) * 100, 2),\n",
    "        'iou': round(np.mean(iou_scores) * 100, 2),\n",
    "        'accuracy': round(np.mean(accuracy_scores) * 100, 2)\n",
    "    }\n",
    "\n",
    "all_eval_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    metrics = evaluate_model(model, test_loader, device)\n",
    "    all_eval_results[name] = metrics\n",
    "    print(f\"{name} - Dice: {metrics['dice']}%, IoU: {metrics['iou']}%, Acc: {metrics['accuracy']}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae3c3e-d918-43b5-ab82-04939b256622",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
